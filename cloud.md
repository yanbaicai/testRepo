

磁盘驱动器： 

​              寻址时间-磁头移动到特定位置进行读写操作的工序 ；

​              传输速率-对应磁盘的带宽；

数据的访问模式受限于磁盘的寻址，势必导致花更多时间读写大部分数据；

RDBMS - Mapreduce适合：一次写入多次读取的应用；

关系型数据库适合： 持续更新的数据集；

| —             | DB                 | RDBMS          |
| ------------- | ------------------ | -------------- |
| 数据大小      | GB                 | TB             |
| 访问模式      | 交互/批处理        | 批处理         |
| 集成度/伸缩性 | 高、非线性         | 低、线性可伸缩 |
| 数据结构      | 预定义的结构化数据 | 非结构/半结构  |

广义上的高性能计算：将作业分配给集群，这些集群访问共享文件系统，有一个存储区域网络进行管理，这适用于 以主计算密集型的作业；当节点需要访问的数据达到TB级别时，会有网络带宽的瓶颈；

MapReduce: 尝试子啊计算节点本地存储数据，本地访问肯定快；这也是MapReduce性能良好原因之一；

此外，从键值对类型的方式；mapper传输键值对给reducer

在一个大规模分布式计算平台协调进程是一个很大的挑战；最困难的是恰当的处理失效与错误；使用MapReduce时开发人员不用考虑这些；MapRecude会检测失败的map/reduce任务，在其他健康的机器上重新执行； 各个任务之间不会依赖，所以可实现；

![hadoop](D:\常用\md\img\hadoop.png)

~~~
Hadoop的一些子项目：

Core:  分布式文件系统和通用IO组件、接口
Avro:RPC书籍序列系统；持久化数据存储
Mapreduce:分布式数据处理模式和执行环境；
HDFS:分布式文件系统
Pig:一种数据流语言和运行环境，用以检索非常大的数据集；
Hbase：一个分布式的列存储数据库；Hbase使用HDFS做底层存储；
Zookeeper：一个分布式、高可用的协调服务；
Hive：分布式数据仓库。Hive管理HDFS中存储的数据；并提供基于SQL的查询方式；
Churwa: 分布式数据收集和分析系统；
~~~



MapReduce: 并行处理机制

~~~~
  分为： map阶段和reduce阶段，每个阶段都有键值对表示输入和输出；
   map阶段出入就是原始的数据文本；数据准备，也可以在去损；
     键：文件中的行偏移量；
     map函数的输出由MapReduce框架处理，然后再被发送到reduce函数；
     这一处理过程根据键来对键值对进行排序和分组；
  简单例子：
         TODO
~~~~



分布化

~~~~
MapReduce的作业是客户端执行的单元，
          job: 包括输入数据、Maprereduce代码、配置信息
           Hadoop通过作业分成若干个小任务来工作；
有两种类型的节点控制着作业控制着作业执行过程：
         jobtracker 和多个tasktracker   
     jobtracker:通过调度任务在tasktracker上运行；来协调所有运行的作业，记录每项任务的进展；
     tasktracker:进度报告给jobtracker; 
      如果一个任务调度失败，则jobtracker可以重新调度任务到另一个tasktracker
   Hadoop把输入数据分为等长小数据发送到Mapreduce，称为输入分片； hadoop为每一个分片创建一个map任务； 
   分片太小，那么管理分片的总时间和map任务创建的总时间将决定作业的执行总时间；
   对于大多数作业，一个理想的分片往往是一个HDFS块大小，64MB;
   map任务的执行节点和输入数据的存储节点是同一节点，Hadoop性能最佳，这就是 data locality optimization
   map任务把输出写入本地磁盘，而不是HDFS, map输出是中间输出，中间输出则被reduce任务处理后产生最终的输出，一旦作业完成，map输出就可以删除了，写入HDFS浪费；如果一个节点上运行的map任务在map输出给reduce任务处理之前崩溃， 那么Hadoop会在另一个节点重新运行map任务以再次创建map的输出；
   reduce不具备数据本地读取的优势，-- 一个单一的reduce任务输入来自所有mapper的输出组成； 为增加可靠性，reduce的输出通常存储在HDFS中；
   reduce的数量不是又输入大小决定，是单独具体制定；如果有多个reduce,map输出会进行分区，为每一个reduce任务创建一个partition,每个分区包含许多键；但是每个键的记录都在分区中
  如图：
  多个map任务输出时，与reduce之间的数据流要shuffle,
   
~~~~

![hadoop-1-1](D:\常用\md\img\hadoop-1-1.png)

 此外，还有没有reduce的情形：此时不需要shuffle,

![hadoop-1-2](D:\常用\md\img\hadoop-1-2.png)

  Combiner: 

​        集群的可用带宽限制了mapreduce的作业数量，因此map和reduce之间的传输代价是最小的；Hadoop允许声明一个Combiner,运行在map的输出后；可以为reduce数据做准备等，但是不能取代reduce；因为reduce还需要对来自不同map的相同键进行处理；但是combiner可以减少map和reduce之间的数据传输量；

HDFS ：分布式文件系统

~~~~
HDFS: 以流式数据访问模式存储超大文件而设计的文件系统；
  —— 超大文件： 几百MB  GB TB级别的
  —— 流式数据访问：一次写入、多次读取模式；一个数据集通常由数据源生成，在此基础上进行各种各样的分析；每次分析都会设计到数据集的大部分数据，所以读取整个数据集的时间的延迟更为很重要
  —— 低延迟数据访问: 低延迟访问数据在ms范文内的用HDFS并不适合；HDFS是为达到高数据吞吐量而优化
  ——大量的小文件：
      namenode存储着文件系统的元数据，因为文件数量的限制也有名称节点的内存量而决定；一般而言，索引目录以及块占大约150B ; 100文件一个文件占一个块，至少300MB的内存；
  ——多用户写入，任意修改文件：不支持
       HDFS的文件只有一个写入者，而且写操作总是在文件的末尾；
  ---------------一些概念--------------------------------
 块： HDFS中的块默认64MB，与磁盘类似，HDFS文件也被分为以块为单元的block，作为单数的单元存储；
  （磁盘的块仅有521B, HDFS之所以这么大死为了减少寻址开销；一个块足够大，从磁盘转移数据的时间能够远远大于定位这个块开始端的时间）    
  分布式文件系统的抽象块的好处：
      1、文件可以大于网络中任意一个磁盘的容量；clock不需要存在在统一个磁盘上；
      2.使用块抽象单元而不是文件会简化存储子系统； 
      3.块很适合为提供容错和实用性的复制操作；
名称节点与数据节点：
  HDFS集群以一个名称节点和多个数据及诶单的模式运行
    名称节点(管理者)： 
        记录每个文件的每个块所在的数据节点
        管理文件系统的命名空间，维护这个文件系统树和这个树所有的文件和索引目录；这些信息两种方式持久化：命名空间镜像化和log ；一般的配置选择：本地磁盘写入的同时，写入一个远程NFS挂载；
    数据节点(工作者)：
        存储并提供定位块的服务；并定时的向名称节点发送他们存储块的列表；
                 
~~~~



